---
title: 'Data Analysis Project'
author: "STAT 420, Fall 2024, C. Easton, A. Roh, T. Toter, A. Treptow"
date: 'December xx, 2024'
output:
  html_document:
    theme: readable
    toc: yes
    toc_depth: 2
  pdf_document:
    toc: yes
    toc_depth: 2
urlcolor: cyan
---

# Introduction

In this data analysis study we applied the principles we learned during the semester to iteratively improve a linear regression model.

For our case study, we chose a "Wine Quality" dataset from the UC Irvine Machine Learning Repository. The data relates to red and white variants of the Portuguese vinho verde wine samples. We drew the data from the following site:

  https://archive.ics.uci.edu/dataset/186/wine+quality

Each row in the dataset of wine samples contains a record of 11 numerically measured physicochemical attributes, such as acidity, residual sugar, chlorides, and pH. We combined two datasets (one for white wine and one for red wine), resulting in an additional categorical attribute for wine type.

The 12 attributes listed above served as our source predictor variables. A final attribute from the dataset measures quality, and serves as our response variable. Each quality measurement is a subjectively-assigned integer, ranging from 1 to 10. Our goal was to build a model that could use the objectively measured predictors as inputs to estimate how a human would rate each wine.




```{r setup}
options(repos = c(CRAN = "https://cloud.r-project.org"))

```

# Methods

## Data preparation

#### Load and Examine the Data

```{r message=FALSE, warning=FALSE}
library(dplyr)

red_wine = read.csv("winequality-red.csv", sep = ";")
white_wine = read.csv("winequality-white.csv", sep = ";")
# Add categorical variables for wine type
red_wine$type = "Red"
white_wine$type = "White"
wine_data = bind_rows(red_wine, white_wine) # Combine the two datasets
wine_data$type = as.factor(wine_data$type)
str(wine_data)
```

#### Remove Outliers

A few data points departed noticeably from the vast majority of the rest of the data.  We removed some obvious outliers to allow us to pursue a model that handles the remainder of the data.

We simply view the data in a table. Then, we simply view columns from biggest to smallest values, and notice that there is a wine observation with a residual sugar value of 65.80, more than double that of the next wine observation.

```{r}
desc_res_sugar = wine_data[order(wine_data$residual.sugar, decreasing = TRUE), ]
head(desc_res_sugar, n = 3)
```

We repeat this again for the free sulfur dioxide column, and notice that the wine observation has almost double the value as the next observation.

```{r}
desc_free_sulf_dio = wine_data[order(wine_data$free.sulfur.dioxide, decreasing = TRUE), ]
head(desc_free_sulf_dio, n = 3)
```

Keeping these data will hinder our ability to read and interpret the pairs plots, so we remove them.

```{r message=FALSE, warning=FALSE}
res_sugar_6580 = which(wine_data$residual.sugar == 65.80)
free_sulf_dio_289 = which(wine_data$free.sulfur.dioxide == 289.0)

remove_idx = c(res_sugar_6580, free_sulf_dio_289)
wine_data = wine_data[-remove_idx, ]
```


#### Split Data Into Train and Test

We performed an 80/20 test/train split on the data so that we can later check for over-fitting by training to unseen data. 

```{r}
set.seed(123)
trn_idx = sample(nrow(wine_data), size = 0.8 * nrow(wine_data))
wine_data_trn = wine_data[trn_idx, ]
wine_data_tst = wine_data[-trn_idx, ]
```


## Fit a Full Additive Model

We began by creating an additive model using all predictors without transformations. This model served as baseline to judge improvements for upcoming iterations.

```{r message=FALSE, warning=FALSE}
full_add_model = lm(quality ~ ., data = wine_data_trn)
summary(full_add_model)
```


This initial model had an Adjusted R-squared value of 0.2931, and we sought to improve on that. 

## Log Transform Predictors

To check whether some predictors should be log transformed, we began by fitting a model which was the additive model plus logs of all the variables besides citric acid (which had zero values). 

```{r message=FALSE, warning=FALSE}
model_add = lm(quality ~ ., data = wine_data_trn)

model_add_log = lm(
  quality ~ fixed.acidity + log(fixed.acidity) +
    volatile.acidity + log(volatile.acidity) +
    citric.acid  +
    residual.sugar + log(residual.sugar) +
    chlorides + log(chlorides) +
    free.sulfur.dioxide + log(free.sulfur.dioxide) +
    total.sulfur.dioxide + log(total.sulfur.dioxide) +
    density + log(density) +
    pH + log(pH) +
    sulphates + log(sulphates) +
    alcohol + log(alcohol) +
    type,
  data = wine_data_trn
)

coefficients(model_add_log)


```

In the summary of the model, we identified volatile.acidity, residual.sugar, free.sulfur.dioxide and total.sulfur.dioxide as predictors that had smaller p values when log transformed. 

We then created 4 separate models, each with a single, different of these variable logged. This will allow us to compare against the additive model. 


```{r message=FALSE, warning=FALSE}


model_log1 = lm(quality ~ fixed.acidity + log(volatile.acidity) + citric.acid + 
                 residual.sugar + chlorides + free.sulfur.dioxide + 
                 total.sulfur.dioxide + density + pH + sulphates + 
                 alcohol + type, data = wine_data_trn)
                 
model_log2 = lm(quality ~ fixed.acidity + volatile.acidity + citric.acid + 
                 log(residual.sugar) + chlorides + free.sulfur.dioxide + 
                 total.sulfur.dioxide + density + pH + sulphates + 
                 alcohol + type, data = wine_data_trn)
                 
model_log3 = lm(quality ~ fixed.acidity + volatile.acidity + citric.acid + 
                 residual.sugar + chlorides + log(free.sulfur.dioxide) + 
                 total.sulfur.dioxide + density + pH + sulphates + 
                 alcohol + type, data = wine_data_trn)
                 
model_log4 = lm(quality ~ fixed.acidity + volatile.acidity + citric.acid + 
                 residual.sugar + chlorides + free.sulfur.dioxide + 
                 log(total.sulfur.dioxide) + density + pH + sulphates + 
                 alcohol + type, data = wine_data_trn)

summary(model_add)$adj.r.squared
summary(model_log1)$adj.r.squared
summary(model_log2)$adj.r.squared
summary(model_log3)$adj.r.squared
summary(model_log4)$adj.r.squared


```

We noted improvement in adjusted r squared when free.sulfur.dioxide and volatile.acidity were logged. These two were then log transformed in further models.


```{r message=FALSE, warning=FALSE}

model_log = lm(quality ~ fixed.acidity + log(volatile.acidity) + citric.acid + 
                 residual.sugar + chlorides + log(free.sulfur.dioxide) + 
                 total.sulfur.dioxide + density + pH + sulphates + 
                 alcohol + type, data = wine_data_trn)


summary(model_log)$adj.r.squared

```

The adjusted r squared of this model was higher than any of the 4 previous models compared. 


## Examine quadratic transformation of non-logged variables.

To see whether any of our predictors could be improved by a quadratic transformation, we applied such a transformation to all of the non-logged variables from our best model. 

```{r}
model_squared = lm(
  quality ~ fixed.acidity + I(fixed.acidity^2) +
    log(volatile.acidity) +
    citric.acid + I(citric.acid^2) +
    residual.sugar + I(residual.sugar^2) +
    chlorides + I(chlorides^2) +
    log(free.sulfur.dioxide) +
    total.sulfur.dioxide + I(total.sulfur.dioxide^2) +
    pH + I(pH^2) +
    sulphates + I(sulphates^2) +
    alcohol + I(alcohol^2) +
    type,
  data = wine_data)
  
# summary(model_squared)


n = nrow(wine_data)
model_squared_bic = step(
  model_squared,
  direction = "backward",
  k = log(n), trace = FALSE  # BIC criterion
)

summary(model_squared_bic)
```

Alcohol looked like it could benefit from being squared as the p value for I(alcohol^2) much smaller than alchohol and coefficient larger as well. So we updated our best model to have alchohol squared, but there was no improvement in model performance. We didnt find any other variables that improved performance when squared, though we tested a few. 

```{r}


model_log_quad = lm(quality ~ fixed.acidity + log(volatile.acidity) + citric.acid + 
                 residual.sugar + chlorides + log(free.sulfur.dioxide) + 
                 total.sulfur.dioxide + density + pH + sulphates + 
                 I(alcohol^2) + type, data = wine_data_trn)

summary(model_log_quad)$adj.r.squared

```

There was some improvement in adjusted r squared when alchohol was squared. However an anova test failed to reject the null hypothesis that the simpler model explains the data, so we chose not to include this squared term in our model. 

```{r}

anova(model_log,model_log_quad)

```


## Multicollinearity 

#### Variance Inflation Factors (VIF) 
```{r}


```{r message=FALSE, warning=FALSE}

if (!require(car)) install.packages("car")
library(car)
vif_values = vif(model_log)
vif_values


```

We saw a lot of multicollinearity in our data with density, residual.sugar, and type all over a VIF of 5. We looked to a heatmap to understand how variables might be connected. 

#### Predictor Correlation Heatmap


```{r message=FALSE, warning=FALSE}
if (!require(corrplot)) install.packages("corrplot")
library(corrplot)

numeric_data = wine_data_trn %>%
  select(-type, -quality) # Considers numeric predictors only
cor_matrix = cor(numeric_data, use = "complete.obs")
par(mar = c(0, 0, 5, 0))
corrplot(cor_matrix, 
         method = "color", 
         addCoef.col = "black", 
         tl.cex = 0.9,
         tl.col = "black",
         tl.srt = 45,
         number.cex = 0.7,
         main = "Correlation Heatmap", 
         cl.cex = 0.8,
         cl.ratio = 0.2,
         mar = c(0, 0, 1, 0),
         col = colorRampPalette(c("navy", "white", "brown"))(200)
)
```


We noticed that density was highly related to many other variables. We tried removing density to see if that improved multicollinearity in our model.

``` {r}

model_log_noD = lm(quality ~ fixed.acidity + log(volatile.acidity) + citric.acid + 
                 residual.sugar + chlorides + log(free.sulfur.dioxide) + 
                 total.sulfur.dioxide + pH + sulphates + 
                 alcohol + type, data = wine_data_trn)

vif_values = vif(model_log_noD)
vif_values


```


## Summary of performance for various tested models

```{r message=FALSE, warning=FALSE}
summary(model_add)$adj.r.squared
summary(model_log)$adj.r.squared
summary(model_log_noD)$adj.r.squared
```


We choose our no-density model as our best model so far, as it significantly improved our VIF values while maintaining a high adjusted r squared value relative to our other models.



## Interaction terms

Although we had already lowered our VIF values to a reasonable range, we thought that there might be some remiaining interconnectedness between varibales that, if accounted for with interaction terms, might improve the predictive power of our model. So we applied interaction terms between all our variables and used various strategies to select those which improved our model. 


``` {r}

model_log_int = lm(quality ~ (fixed.acidity + log(volatile.acidity) + 
                                citric.acid + residual.sugar + chlorides + 
                                log(free.sulfur.dioxide) + 
                                total.sulfur.dioxide + pH + 
                                sulphates + alcohol + type)^2, 
                   data = wine_data_trn)

```


#### Akaike Information Criterion (AIC) and Bayesian Information Criteria (BIC) Modelling

We used back AIC and BIC to select predictors. 

```{r message=FALSE, warning=FALSE}
model_bac_aic = step(model_log_int, trace = 0)
model_bac_bic = step(model_log_int, k = log(nrow(wine_data_trn)), trace = 0)


```



## Analysis of Variance (ANOVA)

We now have 3 potential interaction models. The full interactive model has 66 predictors, and our backwards AIC and BIC models have 44 and 27, respectively. 


```{r}

num_predictors = data.frame(
  Model = c("model_log_noD", "model_log_int", "model_bac_aic", "model_bac_bic"),
  `Number of Predictors` = c(
    length(model_log_noD$coefficients) - 1,
    length(model_log_int$coefficients) - 1,
    length(model_bac_aic$coefficients) - 1,
    length(model_bac_bic$coefficients) - 1
  )
)

# Print the table
print(num_predictors)

```

We ran anovas between the models to determine which was best. 

```{r message=FALSE, warning=FALSE}

anova(model_bac_aic, model_log_noD)[["Pr(>F)"]]
anova(model_bac_bic, model_log_noD)[["Pr(>F)"]]
anova(model_log_int, model_log_noD)[["Pr(>F)"]]

```

All three of our interactive models were shown to be better than our non-additive model as anova tests between all three and the additive model yielded small p values (<0.05) such that the null hypothesis was rejected. 

```{r message=FALSE, warning=FALSE}

anova(model_bac_bic, model_bac_aic)[["Pr(>F)"]]
anova(model_bac_aic, model_log_int)[["Pr(>F)"]]
anova(model_bac_bic, model_log_int)[["Pr(>F)"]]

```

Anovas between the interactive models provided additional information. Anova between the aic and bic models had a very small p value indicating the more complex model (aic) was better. Aic versus model_log_int had a large p value indicating that the smaller aic model was better. Bac_bic was not significantly better than model_log_int. As a result we took the model_bac_aic which also had the highest adjusted r squared at 0.358. 

```{r message=FALSE, warning=FALSE}

# Create a table with adjusted R-squared values
adj_r_squared_table = data.frame(
  Model = c("model_bac_aic", "model_bac_bic", "model_log_int"),
  `Adjusted R-squared` = c(
    summary(model_bac_aic)$adj.r.squared,
    summary(model_bac_bic)$adj.r.squared,
    summary(model_log_int)$adj.r.squared
  )
)

print(adj_r_squared_table)


```


## Remove more outliers

With a solid model to build upon, we used cook's distance to remove more outliers in the model. 


```{r}


mod_cd = cooks.distance(model_bac_aic)

model_bac_aic_cd = lm(formula(model_bac_aic), data = wine_data_trn,
                 subset = mod_cd < 4 / length(mod_cd))

summary(model_bac_aic_cd)$adj.r.squared

model_bac_aic = model_bac_aic_cd

```


# Results




## Linear Model Assumption Diagnostic Plots

A Residuals versus fitted plot showed that the data was pretty well evenly distributed, perhaps with some clustering in the middle of the graph that could have to do with the subjective grading scale of the response. 

```{r message=FALSE, warning=FALSE}
plot(model_bac_aic, which = 1, main = "Residuals vs Fitted")
```

Our Normal Q-Q plot indicated that the residuals were normally distributed as most points fell along the center line. 

```{r message=FALSE, warning=FALSE}
plot(model_bac_aic, which = 2, main = "Normal Q-Q Plot")
```

## Evaluating our Model

```{r}
get_loocv_rmse = function(model) {
  sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}
```

```{r}
rmse = function(actual, predicted) {
  sqrt(mean((actual - predicted)^2))
}
```

```{r}
rmse(wine_data_trn$quality, predict(model_bac_aic, wine_data_trn))
rmse(wine_data_tst$quality, predict(model_bac_aic, wine_data_tst))
```


# Discussion

We arrived at our best model through a backward step AIC upon an interaction model, containing transformations on selected predictors.

To arrive at this model, we took the steps of examining a full additive model, log transforming the variables with skewed distributions, addressing multicollinearity between predictors, experimenting with polynomial terms and interactions, exploring improvements through AIC and BIC modeling, and verifying our progress through ANOVA comparison.

With each new candidate model, we analyzed how it compared to its predecessor models to assess whether we were headed in a productive direction. We reviewed the summaries of the candidate models, carefully considering outputs such as p-values and adjusted R-squared, to guide our next steps for how to adjust to a better model.

(TODO: Insert relevant measurements for the performance of the model.)

This model achieved an Adjusted R-squared of `r summary(model_bac_aic)$adj.r.squared`.

Performing backward BIC delivered a result of `r length(model_bac_aic$coefficients)` coefficients, but...
(TODO: )

Importantly, we did a final check on our final model to ensure that it obeyed the linear model assumptions.
